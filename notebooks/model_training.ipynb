{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e08277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b841a",
   "metadata": {},
   "source": [
    "üîπ What‚Äôs left / next steps\n",
    "\n",
    "Class distribution / skewness Done \n",
    "\n",
    "Check label counts ‚Üí compute % per class Done\n",
    "\n",
    "Merge similar attacks (e.g., SSH + FTP Bruteforce ‚Üí ‚ÄúBruteforce‚Äù) Done\n",
    "\n",
    "Feature scaling\n",
    "\n",
    "Neural networks are sensitive to numeric ranges\n",
    "\n",
    "Apply StandardScaler or MinMaxScaler to all numeric columns\n",
    "\n",
    "Categorical encoding\n",
    "\n",
    "Protocol ‚Üí one-hot or label encoding\n",
    "\n",
    "Dst_Port ‚Üí optional: one-hot top N ports, merge rare ports into ‚Äúother‚Äù\n",
    "\n",
    "Train/test split\n",
    "\n",
    "Stratified by Label\n",
    "\n",
    "Recommended: 80% train / 20% test\n",
    "\n",
    "Class imbalance handling\n",
    "\n",
    "Optional but recommended:\n",
    "\n",
    "Use class weights in NN loss function\n",
    "\n",
    "Or oversample rare attack classes\n",
    "\n",
    "Optional feature engineering / selection\n",
    "\n",
    "Check correlation ‚Üí remove extremely redundant features\n",
    "\n",
    "Create engineered temporal features from Timestamp if desired (hour, day of week)\n",
    "\n",
    "Final sanity checks\n",
    "\n",
    "No NaNs, inf, or placeholder negatives remain\n",
    "\n",
    "All features are numeric and scaled\n",
    "\n",
    "Categorical features encoded\n",
    "\n",
    "Labels merged/encoded and consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44a4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=  pd.read_csv(r\"/root/Cyber/Cyber_security/datasets/02-14-2018_uncleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7f3937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "benign            63.544031\n",
       "bruteforce        18.503838\n",
       "ssh-bruteforce    17.952131\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts(normalize=True)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3a5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"]=df[\"Label\"].replace([\"ssh-bruteforce\"],\"bruteforce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b97337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "benign        63.544031\n",
       "bruteforce    36.455969\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts(normalize=True)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fb942",
   "metadata": {},
   "source": [
    "WE WILL USE STANDARD SCALER BECAUSE MOST OF  THE PAPERS HAVE USED STANDARD SCALER WHICH USES Z SCORE NORMALIZATION\n",
    "AND BECAUSE NETWORK TRAFFIC CAN HAVE VERY HIGH OUTLIERS AND MIN MAX SQUASHES THEM INTO A TINY RANGE , BEFORE SCALING WE NEED TO SPLIT THE DATA INTO TRAIN TEST SPLIT DUE TO DATA LEAKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85c5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "top_ports = df[\"Dst_Port\"].value_counts().nlargest(K).index\n",
    "\n",
    "df[\"Dst_Port\"] = df[\"Dst_Port\"].where(\n",
    "    df[\"Dst_Port\"].isin(top_ports),\n",
    "    \"Other\"\n",
    ")\n",
    "\n",
    "df[\"Dst_Port\"] = df[\"Dst_Port\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f665653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dst_Port\n",
      "53       198117\n",
      "21       193422\n",
      "22       187881\n",
      "80       129625\n",
      "Other     93741\n",
      "443       92094\n",
      "3389      90606\n",
      "445       40304\n",
      "0         11876\n",
      "5355       5083\n",
      "137        2191\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Dst_Port\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220d0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"]=df[\"Label\"].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6fd3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "benign        663997\n",
       "bruteforce    380943\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf0be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label_encoded'] = df['Label'].map({'benign': 0, 'bruteforce': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c022925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    663997\n",
       "1    380943\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label']=df[\"Label_encoded\"]\n",
    "df.drop(columns=[\"Label_encoded\"],inplace=True)\n",
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "757b7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ba0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_cols = [\"Protocol\", \"Dst_Port\"]\n",
    "\n",
    "numeric_cols = df.drop(columns=[\"Label\", \"Protocol\", \"Dst_Port\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555f7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(\n",
    "            drop=\"first\",          # avoids dummy trap\n",
    "            handle_unknown=\"ignore\",\n",
    "            sparse_output=False\n",
    "        ), onehot_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9f692dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Label\"])\n",
    "y = df[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ab682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dst_Port\n",
       "<class 'str'>    1044940\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "df[\"Dst_Port\"].apply(type).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3419ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X_train_proc))\n",
    "type(X_test_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ab010c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff1d9a",
   "metadata": {},
   "source": [
    "Checklist \n",
    "\n",
    "Understand & Prepare Data ‚úîÔ∏è\n",
    "\n",
    "Collect dataset, clean & preprocess ‚úîÔ∏è\n",
    "\n",
    "Split into train/validation/test sets  ‚úîÔ∏è\n",
    "\n",
    "Normalize/scale features ‚úîÔ∏è\n",
    "\n",
    "Batch the data\n",
    "\n",
    "Define Model Architecture\n",
    "\n",
    "Decide number & type of layers\n",
    "\n",
    "Choose activation functions\n",
    "\n",
    "Think about input & output shapes\n",
    "\n",
    "Choose Loss Function & Optimizer\n",
    "\n",
    "Pick a loss suitable for task (classification/regression)\n",
    "\n",
    "Select optimizer (Adam, SGD, etc.)\n",
    "\n",
    "Set learning rate & other hyperparameters\n",
    "\n",
    "Train the Model\n",
    "\n",
    "Loop over epochs and batches\n",
    "\n",
    "Forward pass ‚Üí compute loss ‚Üí backward pass ‚Üí update weights\n",
    "\n",
    "Monitor training loss & metrics\n",
    "\n",
    "Validate & Evaluate\n",
    "\n",
    "Test on unseen data\n",
    "\n",
    "Calculate accuracy, F1, RMSE, or other metrics\n",
    "\n",
    "Adjust model or hyperparameters if needed\n",
    "\n",
    "Save & Deploy\n",
    "\n",
    "Save model weights\n",
    "\n",
    "Load model for inference or further training\n",
    "\n",
    "Iterate & Improve\n",
    "\n",
    "Tune hyperparameters\n",
    "\n",
    "Experiment with architecture\n",
    "\n",
    "Handle overfitting (dropout, regularization)\n",
    "\n",
    "Scale up data if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9011c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1=y_train.to_numpy()\n",
    "y_test1=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5bc1dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_809/1397678349.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train=torch.tensor(X_train,dtype=torch.float32)\n",
      "/tmp/ipykernel_809/1397678349.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test=torch.tensor(X_test,dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3221, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3234, -0.0722, -0.0309,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.3228, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.3234, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3234, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3235, -0.0945, -0.0593,  ...,  0.0000,  0.0000,  1.0000]])\n",
      "tensor([[-2.4156e-01,  3.9714e-02, -2.5028e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.2346e-01, -1.1692e-01, -5.9349e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.2346e-01, -1.1692e-01, -5.9349e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 4.0432e+00,  2.1872e-01,  6.3818e-02,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00],\n",
      "        [ 1.9700e+00,  1.9634e-01,  7.3292e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.2346e-01, -1.1692e-01, -5.9349e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "tensor([0., 1., 1.,  ..., 0., 0., 1.])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_809/1397678349.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_test=torch.tensor(Y_test , dtype=torch.float32)\n",
      "/tmp/ipykernel_809/1397678349.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_train=torch.tensor(Y_train , dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "X_train=torch.from_numpy(X_train_proc)\n",
    "X_test=torch.from_numpy(X_test_proc)\n",
    "Y_test=torch.from_numpy(y_test1)\n",
    "Y_train=torch.from_numpy(y_train1)\n",
    "X_train=torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test=torch.tensor(X_test,dtype=torch.float32)\n",
    "Y_test=torch.tensor(Y_test , dtype=torch.float32)\n",
    "Y_train=torch.tensor(Y_train , dtype=torch.float32)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(Y_train)\n",
    "print(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c87a901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "num_epoch=30\n",
    "batch_size=1024\n",
    "lr= 1e-3\n",
    "input_dim=X_train.shape[1]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset  = TensorDataset(X_test, Y_test)\n",
    "\n",
    "\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23e55878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1024, 70])\n",
      "Labels batch shape: torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "train_features,train_labels=next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b06ef637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute class weights and use in loss function \n",
    "num_pos=(Y_train==1).sum()\n",
    "num_neg=(Y_train==0).sum()\n",
    "pos_weight=num_neg/num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41a4475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dcb2e9",
   "metadata": {},
   "source": [
    "Baseline Model Architecture\n",
    "\n",
    "Input: n_features\n",
    "\n",
    "Input Layer\n",
    "\n",
    "Linear(n_features ‚Üí 128)\n",
    "\n",
    "BatchNorm1d(128)\n",
    "\n",
    "ReLU\n",
    "\n",
    "Dropout(p = 0.3)\n",
    "\n",
    "Hidden Layer 1\n",
    "\n",
    "Linear(128 ‚Üí 64)\n",
    "\n",
    "BatchNorm1d(64)\n",
    "\n",
    "ReLU\n",
    "\n",
    "Dropout(p = 0.3)\n",
    "\n",
    "Hidden Layer 2\n",
    "\n",
    "Linear(64 ‚Üí 32)\n",
    "\n",
    "ReLU\n",
    "\n",
    "Output Layer\n",
    "\n",
    "Linear(32 ‚Üí 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "936b4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruteForceNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Uses 2 Hidden layers with dropout = 0.03 and BatchNorm1d\n",
    "    Relu as an activation function and loss is BCELogitLoss with class weights\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.model=nn.Sequential(\n",
    "            #Input layer\n",
    "            nn.Linear(input_dim,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.03),\n",
    "\n",
    "            #Hidden layer \n",
    "\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.03),\n",
    "\n",
    "            #Hidden layer 2\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            #Output layer\n",
    "            nn.Linear(32,1)            \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.model(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3f1d72cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=BruteForceNN(input_dim=input_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6910fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=None\n",
    "if torch.cuda.is_available():\n",
    "    device=\"cuda\"\n",
    "else:\n",
    "    device=\"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2dd3caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "56048264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 | Train Loss: 0.0002 | Val Loss: 0.0002 | ROC-AUC: 1.0000 | Precision: 0.9999 | Recall: 1.0000\n",
      "Epoch 2/30 | Train Loss: 0.0001 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 0.9999 | Recall: 1.0000\n",
      "Epoch 3/30 | Train Loss: 0.0001 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 0.9999 | Recall: 1.0000\n",
      "Epoch 4/30 | Train Loss: 0.0001 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 5/30 | Train Loss: 0.0001 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 6/30 | Train Loss: 0.0002 | Val Loss: 0.0005 | ROC-AUC: 1.0000 | Precision: 0.9993 | Recall: 1.0000\n",
      "Epoch 7/30 | Train Loss: 0.0001 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 8/30 | Train Loss: 0.0000 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 9/30 | Train Loss: 0.0000 | Val Loss: 0.0002 | ROC-AUC: 1.0000 | Precision: 0.9999 | Recall: 1.0000\n",
      "Epoch 10/30 | Train Loss: 0.0001 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 0.9999 | Recall: 1.0000\n",
      "Epoch 11/30 | Train Loss: 0.0000 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 12/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 13/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 14/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 15/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 16/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 17/30 | Train Loss: 0.0001 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 0.9999 | Recall: 1.0000\n",
      "Epoch 18/30 | Train Loss: 0.0001 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 19/30 | Train Loss: 0.0000 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 20/30 | Train Loss: 0.0001 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 21/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 22/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 23/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 24/30 | Train Loss: 0.0000 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 0.9999 | Recall: 1.0000\n",
      "Epoch 25/30 | Train Loss: 0.0001 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 26/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 27/30 | Train Loss: 0.0002 | Val Loss: 0.0001 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 28/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 29/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n",
      "Epoch 30/30 | Train Loss: 0.0000 | Val Loss: 0.0000 | ROC-AUC: 1.0000 | Precision: 1.0000 | Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float(\"inf\")  \n",
    "\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "\n",
    "    # ----- TRAINING -----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for X_batch, Y_batch in train_dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        Y_batch = Y_batch.to(device).float().unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X_batch)\n",
    "        loss = criterion(logits, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_loss = running_loss / len(train_dataloader)  # after loop\n",
    "\n",
    "    # ----- VALIDATION -----\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch in test_dataloader:\n",
    "            X_batch = X_batch.to(device).float()\n",
    "            Y_batch = Y_batch.to(device).float().unsqueeze(1)\n",
    "\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, Y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(logits)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(Y_batch.cpu())\n",
    "\n",
    "    val_loss = val_loss / len(test_dataloader)  # after loop\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_preds_class = (all_preds > 0.5).astype(int)\n",
    "\n",
    "    # ----- METRICS -----\n",
    "    roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds_class)\n",
    "    recall = recall_score(all_labels, all_preds_class)\n",
    "\n",
    "    # ----- SAVE BEST MODEL -----\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epoch} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "          f\"ROC-AUC: {roc_auc:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84eb51e",
   "metadata": {},
   "source": [
    "# Final Remarks\n",
    "\n",
    "## Summary\n",
    "We developed a neural network-based IDS specialized for brute-force attacks using the CIC‚ÄëIDS 2018 02‚Äë14 dataset. After preprocessing, balancing, and scaling the features, the model achieved near-perfect performance on validation data with ROC-AUC, precision, and recall all ‚âà1.0.\n",
    "\n",
    "## Scope & Limitations\n",
    "This model is attack-specific ‚Äî it is trained solely on brute-force patterns. It **does not generalize** to other attacks such as DoS, botnets, or reconnaissance unless retrained with those classes. Results reflect dataset simplicity and class separability.\n",
    "\n",
    "## Future Work\n",
    "- Extend to a **multi-class IDS** covering other attack types (DoS, botnets, etc.).\n",
    "- Explore **open-set anomaly detection** to identify unseen attacks.\n",
    "- Compare neural network performance with traditional ML models like Random Forest or XGBoost.\n",
    "\n",
    "## Reproducibility\n",
    "The code, preprocessing pipeline, and training scripts are included. The trained model file is not uploaded due to size constraints but can be generated using the included notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2143024",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsdl-text-recognizer-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
