{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e08277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b841a",
   "metadata": {},
   "source": [
    "üîπ What‚Äôs left / next steps\n",
    "\n",
    "Class distribution / skewness Done \n",
    "\n",
    "Check label counts ‚Üí compute % per class Done\n",
    "\n",
    "Merge similar attacks (e.g., SSH + FTP Bruteforce ‚Üí ‚ÄúBruteforce‚Äù) Done\n",
    "\n",
    "Feature scaling\n",
    "\n",
    "Neural networks are sensitive to numeric ranges\n",
    "\n",
    "Apply StandardScaler or MinMaxScaler to all numeric columns\n",
    "\n",
    "Categorical encoding\n",
    "\n",
    "Protocol ‚Üí one-hot or label encoding\n",
    "\n",
    "Dst_Port ‚Üí optional: one-hot top N ports, merge rare ports into ‚Äúother‚Äù\n",
    "\n",
    "Train/test split\n",
    "\n",
    "Stratified by Label\n",
    "\n",
    "Recommended: 80% train / 20% test\n",
    "\n",
    "Class imbalance handling\n",
    "\n",
    "Optional but recommended:\n",
    "\n",
    "Use class weights in NN loss function\n",
    "\n",
    "Or oversample rare attack classes\n",
    "\n",
    "Optional feature engineering / selection\n",
    "\n",
    "Check correlation ‚Üí remove extremely redundant features\n",
    "\n",
    "Create engineered temporal features from Timestamp if desired (hour, day of week)\n",
    "\n",
    "Final sanity checks\n",
    "\n",
    "No NaNs, inf, or placeholder negatives remain\n",
    "\n",
    "All features are numeric and scaled\n",
    "\n",
    "Categorical features encoded\n",
    "\n",
    "Labels merged/encoded and consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a44a4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=  pd.read_csv(r\"/root/Cyber/Cyber_security/datasets/02-14-2018_uncleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7f3937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "benign            63.544031\n",
       "bruteforce        18.503838\n",
       "ssh-bruteforce    17.952131\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts(normalize=True)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3a5992",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"]=df[\"Label\"].replace([\"ssh-bruteforce\"],\"bruteforce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58b97337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "benign        63.544031\n",
       "bruteforce    36.455969\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label.value_counts(normalize=True)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95fb942",
   "metadata": {},
   "source": [
    "WE WILL USE STANDARD SCALER BECAUSE MOST OF  THE PAPERS HAVE USED STANDARD SCALER WHICH USES Z SCORE NORMALIZATION\n",
    "AND BECAUSE NETWORK TRAFFIC CAN HAVE VERY HIGH OUTLIERS AND MIN MAX SQUASHES THEM INTO A TINY RANGE , BEFORE SCALING WE NEED TO SPLIT THE DATA INTO TRAIN TEST SPLIT DUE TO DATA LEAKAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a85c5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "top_ports = df[\"Dst_Port\"].value_counts().nlargest(K).index\n",
    "\n",
    "df[\"Dst_Port\"] = df[\"Dst_Port\"].where(\n",
    "    df[\"Dst_Port\"].isin(top_ports),\n",
    "    \"Other\"\n",
    ")\n",
    "\n",
    "df[\"Dst_Port\"] = df[\"Dst_Port\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f665653f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dst_Port\n",
      "53       198117\n",
      "21       193422\n",
      "22       187881\n",
      "80       129625\n",
      "Other     93741\n",
      "443       92094\n",
      "3389      90606\n",
      "445       40304\n",
      "0         11876\n",
      "5355       5083\n",
      "137        2191\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Dst_Port\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "220d0f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"]=df[\"Label\"].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e6fd3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "benign        663997\n",
       "bruteforce    380943\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf0be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Label_encoded'] = df['Label'].map({'benign': 0, 'bruteforce': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c022925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0    663997\n",
       "1    380943\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Label']=df[\"Label_encoded\"]\n",
    "df.drop(columns=[\"Label_encoded\"],inplace=True)\n",
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "757b7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ba0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_cols = [\"Protocol\", \"Dst_Port\"]\n",
    "\n",
    "numeric_cols = df.drop(columns=[\"Label\", \"Protocol\", \"Dst_Port\"]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555f7268",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(\n",
    "            drop=\"first\",          # avoids dummy trap\n",
    "            handle_unknown=\"ignore\",\n",
    "            sparse_output=False\n",
    "        ), onehot_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9f692dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Label\"])\n",
    "y = df[\"Label\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_test_proc = preprocessor.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ab682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dst_Port\n",
       "<class 'str'>    1044940\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sanity check\n",
    "df[\"Dst_Port\"].apply(type).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3419ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(X_train_proc))\n",
    "type(X_test_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ab010c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ff1d9a",
   "metadata": {},
   "source": [
    "Checklist \n",
    "\n",
    "Understand & Prepare Data ‚úîÔ∏è\n",
    "\n",
    "Collect dataset, clean & preprocess ‚úîÔ∏è\n",
    "\n",
    "Split into train/validation/test sets  ‚úîÔ∏è\n",
    "\n",
    "Normalize/scale features ‚úîÔ∏è\n",
    "\n",
    "Batch the data\n",
    "\n",
    "Define Model Architecture\n",
    "\n",
    "Decide number & type of layers\n",
    "\n",
    "Choose activation functions\n",
    "\n",
    "Think about input & output shapes\n",
    "\n",
    "Choose Loss Function & Optimizer\n",
    "\n",
    "Pick a loss suitable for task (classification/regression)\n",
    "\n",
    "Select optimizer (Adam, SGD, etc.)\n",
    "\n",
    "Set learning rate & other hyperparameters\n",
    "\n",
    "Train the Model\n",
    "\n",
    "Loop over epochs and batches\n",
    "\n",
    "Forward pass ‚Üí compute loss ‚Üí backward pass ‚Üí update weights\n",
    "\n",
    "Monitor training loss & metrics\n",
    "\n",
    "Validate & Evaluate\n",
    "\n",
    "Test on unseen data\n",
    "\n",
    "Calculate accuracy, F1, RMSE, or other metrics\n",
    "\n",
    "Adjust model or hyperparameters if needed\n",
    "\n",
    "Save & Deploy\n",
    "\n",
    "Save model weights\n",
    "\n",
    "Load model for inference or further training\n",
    "\n",
    "Iterate & Improve\n",
    "\n",
    "Tune hyperparameters\n",
    "\n",
    "Experiment with architecture\n",
    "\n",
    "Handle overfitting (dropout, regularization)\n",
    "\n",
    "Scale up data if possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9011c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1=y_train.to_numpy()\n",
    "y_test1=y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bc1dd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3221, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3234, -0.0722, -0.0309,  ...,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.3228, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.3234, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3234, -0.1169, -0.0593,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.3235, -0.0945, -0.0593,  ...,  0.0000,  0.0000,  1.0000]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[-2.4156e-01,  3.9714e-02, -2.5028e-03,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.2346e-01, -1.1692e-01, -5.9349e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.2346e-01, -1.1692e-01, -5.9349e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 4.0432e+00,  2.1872e-01,  6.3818e-02,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00],\n",
      "        [ 1.9700e+00,  1.9634e-01,  7.3292e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-3.2346e-01, -1.1692e-01, -5.9349e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]], dtype=torch.float64)\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n",
      "tensor([0, 1, 1,  ..., 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train=torch.from_numpy(X_train_proc)\n",
    "X_test=torch.from_numpy(X_test_proc)\n",
    "Y_test=torch.from_numpy(y_test1)\n",
    "Y_train=torch.from_numpy(y_train1)\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(Y_train)\n",
    "print(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "num_epoch=30\n",
    "batch_size=1024\n",
    "lr= 1e-3\n",
    "input_dim=X_train.shape[1]\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset  = TensorDataset(X_test, Y_test)\n",
    "\n",
    "\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=batch_size,shuffle=True)\n",
    "train_dataloader=DataLoader(train_dataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23e55878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([1024, 70])\n",
      "Labels batch shape: torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "train_features,train_labels=next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b06ef637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute class weights and use in loss function \n",
    "num_pos=(Y_train==1).sum()\n",
    "num_neg=(Y_train==0).sum()\n",
    "pos_weight=num_neg/num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41a4475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion= nn.BCEWithLogitsLoss(pos_weight=pos_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dcb2e9",
   "metadata": {},
   "source": [
    "Baseline Model Architecture\n",
    "\n",
    "Input: n_features\n",
    "\n",
    "Input Layer\n",
    "\n",
    "Linear(n_features ‚Üí 128)\n",
    "\n",
    "BatchNorm1d(128)\n",
    "\n",
    "ReLU\n",
    "\n",
    "Dropout(p = 0.3)\n",
    "\n",
    "Hidden Layer 1\n",
    "\n",
    "Linear(128 ‚Üí 64)\n",
    "\n",
    "BatchNorm1d(64)\n",
    "\n",
    "ReLU\n",
    "\n",
    "Dropout(p = 0.3)\n",
    "\n",
    "Hidden Layer 2\n",
    "\n",
    "Linear(64 ‚Üí 32)\n",
    "\n",
    "ReLU\n",
    "\n",
    "Output Layer\n",
    "\n",
    "Linear(32 ‚Üí 1)\n",
    "\n",
    "Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b4c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BruteForceNN(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsdl-text-recognizer-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
